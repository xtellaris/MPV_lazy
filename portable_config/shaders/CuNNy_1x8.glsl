// CuNNy 1x8
// Copyright (c) 2024 cunnyplapper

// This program is free software; you can redistribute it and/or
// modify it under the terms of the GNU Lesser General Public
// License as published by the Free Software Foundation; either
// version 3.0 of the License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
// Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public
// License along with this program.  If not, see <https://www.gnu.org/licenses/>.
/* ------------------------------------------------------------------- */


//!DESC [CuNNy_1x8] -in
//!HOOK LUMA
//!COMPUTE 16 8 8 8
//!BIND LUMA
//!SAVE in
//!WIDTH LUMA.w 2 *
//!HEIGHT LUMA.h
//!COMPONENTS 4
//!WHEN OUTPUT.w LUMA.w / 1.2 > OUTPUT.h LUMA.h / 1.2 > *
#extension GL_EXT_shader_explicit_arithmetic_types_float16 : enable
#ifdef GL_EXT_shader_explicit_arithmetic_types_float16
#	define V4 f16vec4
#	define M4 f16mat4
#	define F float16_t
#else
#	define V4 vec4
#	define M4 mat4
#	define F float
#endif
#define l0(x, y) F(LUMA_tex((vec2(clamp(pos + ivec2(x, y), ivec2(0), sz) * ivec2(1, 1) + ivec2(0, 0)) + vec2(0.5)) * LUMA_pt).r)
shared F G[1][10][10];
void hook() {
	ivec2 xy = ivec2(gl_LocalInvocationID.xy);
	ivec2 pos = ivec2(gl_WorkGroupID.xy) * ivec2(8, 8) + xy;
	ivec2 opos = pos * ivec2(2, 1);
	ivec2 sz = ivec2(LUMA_size) - ivec2(1);
	for (int y = 0; y < 10; y += 8) {
		int ay = xy.y + y;
		if (ay >= 10) break;
		for (int x = 0; x < 10; x += 8) {
			int ax = xy.x + x;
			if (ax >= 10) break;
			G[0][ay][ax] = l0(x - 1, y - 1);
		}
	}
	barrier();
	F s0_0_0, s0_0_1, s0_0_2, s0_1_0, s0_1_1, s0_1_2, s0_2_0, s0_2_1, s0_2_2;
	V4 r0, r1;
	r0 = V4(0.0); r1 = V4(0.0);
	s0_0_0 = G[0][xy.y+0][xy.x+0]; s0_0_1 = G[0][xy.y+0][xy.x+1];
	s0_0_2 = G[0][xy.y+0][xy.x+2]; s0_1_0 = G[0][xy.y+1][xy.x+0];
	s0_1_1 = G[0][xy.y+1][xy.x+1]; s0_1_2 = G[0][xy.y+1][xy.x+2];
	s0_2_0 = G[0][xy.y+2][xy.x+0]; s0_2_1 = G[0][xy.y+2][xy.x+1];
	s0_2_2 = G[0][xy.y+2][xy.x+2];
	r0 += V4(-2.590e-01, -6.916e-02, -8.695e-02, 4.579e-02) * s0_0_0;
	r1 += V4(-1.011e-03, -5.351e-02, 1.322e-03, -5.779e-02) * s0_0_0;
	r0 += V4(5.215e-01, 8.069e-01, 2.194e-01, -1.244e-01) * s0_0_1;
	r1 += V4(-7.411e-02, 2.842e-01, 9.047e-03, -1.177e-03) * s0_0_1;
	r0 += V4(2.965e-01, -3.204e-02, -2.998e-02, 8.276e-02) * s0_0_2;
	r1 += V4(5.390e-03, -7.593e-02, -3.475e-03, -9.406e-02) * s0_0_2;
	r0 += V4(6.273e-02, 6.030e-02, -4.528e-02, 2.732e-02) * s0_1_0;
	r1 += V4(-1.293e-02, -2.170e-03, -2.762e-02, -2.548e-01) * s0_1_0;
	r0 += V4(-6.616e-01, -7.680e-01, -3.463e-01, 6.923e-01) * s0_1_1;
	r1 += V4(7.755e-01, -4.254e-01, -6.468e-03, 8.848e-01) * s0_1_1;
	r0 += V4(-3.495e-02, 8.636e-03, 7.056e-02, -7.211e-01) * s0_1_2;
	r1 += V4(-1.209e-01, 1.190e-01, -7.480e-01, -4.461e-01) * s0_1_2;
	r0 += V4(1.691e-01, 3.645e-03, -5.293e-01, -6.158e-02) * s0_2_0;
	r1 += V4(5.323e-02, 7.856e-02, 2.200e-02, -7.446e-02) * s0_2_0;
	r0 += V4(9.381e-02, -3.309e-02, 7.174e-01, 3.197e-02) * s0_2_1;
	r1 += V4(-2.283e-01, -6.426e-01, -8.782e-02, 8.288e-02) * s0_2_1;
	r0 += V4(-1.977e-01, 2.497e-02, 3.354e-02, 2.940e-02) * s0_2_2;
	r1 += V4(9.449e-02, 7.192e-01, 8.418e-01, -1.635e-02) * s0_2_2;
	r0 += V4(-2.231e-03, -1.841e-03, -2.561e-03, 6.261e-04);
	r0 = max(r0, V4(0.0));
	imageStore(out_image, opos + ivec2(0, 0), vec4(r0));
	r1 += V4(6.099e-03, 7.110e-04, -5.396e-03, -2.850e-03);
	r1 = max(r1, V4(0.0));
	imageStore(out_image, opos + ivec2(1, 0), vec4(r1));
}

//!DESC [CuNNy_1x8] -conv1
//!HOOK LUMA
//!COMPUTE 16 8 8 8
//!BIND in
//!BIND LUMA
//!SAVE conv1
//!WIDTH LUMA.w 2 *
//!HEIGHT LUMA.h
//!COMPONENTS 4
//!WHEN OUTPUT.w LUMA.w / 1.2 > OUTPUT.h LUMA.h / 1.2 > *
#extension GL_EXT_shader_explicit_arithmetic_types_float16 : enable
#ifdef GL_EXT_shader_explicit_arithmetic_types_float16
#	define V4 f16vec4
#	define M4 f16mat4
#	define F float16_t
#else
#	define V4 vec4
#	define M4 mat4
#	define F float
#endif
#define l0(x, y) V4(in_tex((vec2(clamp(pos + ivec2(x, y), ivec2(0), sz) * ivec2(2, 1) + ivec2(0, 0)) + vec2(0.5)) * in_pt))
#define l1(x, y) V4(in_tex((vec2(clamp(pos + ivec2(x, y), ivec2(0), sz) * ivec2(2, 1) + ivec2(1, 0)) + vec2(0.5)) * in_pt))
shared V4 G[2][10][10];
void hook() {
	ivec2 xy = ivec2(gl_LocalInvocationID.xy);
	ivec2 pos = ivec2(gl_WorkGroupID.xy) * ivec2(8, 8) + xy;
	ivec2 opos = pos * ivec2(2, 1);
	ivec2 sz = ivec2(LUMA_size) - ivec2(1);
	for (int y = 0; y < 10; y += 8) {
		int ay = xy.y + y;
		if (ay >= 10) break;
		for (int x = 0; x < 10; x += 8) {
			int ax = xy.x + x;
			if (ax >= 10) break;
			G[0][ay][ax] = l0(x - 1, y - 1);
			G[1][ay][ax] = l1(x - 1, y - 1);
		}
	}
	barrier();
	V4 s0_0_0, s0_0_1, s0_0_2, s0_1_0, s0_1_1, s0_1_2, s0_2_0, s0_2_1, s0_2_2, s1_0_0, s1_0_1, s1_0_2, s1_1_0, s1_1_1, s1_1_2, s1_2_0, s1_2_1, s1_2_2;
	V4 r0, r1;
	r0 = V4(0.0); r1 = V4(0.0);
	s0_0_0 = G[0][xy.y+0][xy.x+0]; s0_0_1 = G[0][xy.y+0][xy.x+1];
	s0_0_2 = G[0][xy.y+0][xy.x+2]; s0_1_0 = G[0][xy.y+1][xy.x+0];
	s0_1_1 = G[0][xy.y+1][xy.x+1]; s0_1_2 = G[0][xy.y+1][xy.x+2];
	s0_2_0 = G[0][xy.y+2][xy.x+0]; s0_2_1 = G[0][xy.y+2][xy.x+1];
	s0_2_2 = G[0][xy.y+2][xy.x+2]; s1_0_0 = G[1][xy.y+0][xy.x+0];
	s1_0_1 = G[1][xy.y+0][xy.x+1]; s1_0_2 = G[1][xy.y+0][xy.x+2];
	s1_1_0 = G[1][xy.y+1][xy.x+0]; s1_1_1 = G[1][xy.y+1][xy.x+1];
	s1_1_2 = G[1][xy.y+1][xy.x+2]; s1_2_0 = G[1][xy.y+2][xy.x+0];
	s1_2_1 = G[1][xy.y+2][xy.x+1]; s1_2_2 = G[1][xy.y+2][xy.x+2];
	r0 += M4(-2.462e-02, -6.997e-01, -9.066e-03, -2.459e-02, 7.338e-03, -3.369e-01, 7.152e-02, -1.446e-01, 3.100e-02, 4.139e-01, -4.566e-02, 3.774e-02, 2.176e-02, -8.255e-01, 5.716e-02, -7.604e-03) * s0_0_0;
	r1 += M4(1.284e-01, 2.707e-02, -9.400e-02, -2.989e-02, -6.619e-02, -2.925e-03, -3.903e-02, -3.751e-02, -1.174e-02, -4.978e-03, -2.627e-01, 2.595e-02, -5.699e-02, 3.400e-02, 4.388e-01, 9.522e-02) * s0_0_0;
	r0 += M4(-1.213e-02, -6.896e-01, -1.633e-02, -2.657e-01, -8.422e-02, 7.124e-01, -2.592e-02, -1.087e-01, 3.449e-02, 8.053e-01, -1.027e-01, 7.793e-02, 1.069e-02, -4.877e-02, 9.783e-02, 1.654e-01) * s0_0_1;
	r1 += M4(4.326e-01, 5.703e-04, 8.424e-03, -8.098e-02, -1.385e-01, -2.535e-02, 7.209e-02, -2.704e-02, -3.680e-01, 1.042e-01, 4.328e-02, -1.845e-02, -3.036e-01, 2.560e-02, -1.714e-01, 1.562e-02) * s0_0_1;
	r0 += M4(3.549e-02, -1.851e-01, -4.270e-02, -1.610e-01, -2.187e-02, 3.449e-01, 2.311e-02, 5.300e-02, 2.265e-03, 3.895e-01, 7.382e-03, 4.749e-02, -2.988e-02, 4.520e-02, 8.483e-03, 1.548e-03) * s0_0_2;
	r1 += M4(-3.706e-02, -3.454e-02, -9.811e-02, 1.245e-02, -1.733e-01, 5.373e-02, 1.131e-01, 1.928e-02, 1.852e-01, 8.440e-02, -3.351e-02, 1.520e-01, 1.568e-01, 5.538e-02, -1.255e-01, -1.742e-01) * s0_0_2;
	r0 += M4(5.835e-02, -7.648e-01, 4.721e-02, -3.684e-02, 6.671e-02, 3.792e-01, -2.030e-02, -1.982e-02, -4.337e-02, -2.300e-01, -3.963e-01, -1.935e-02, 1.661e-01, -1.000e+00, -9.436e-02, 2.005e-01) * s0_1_0;
	r1 += M4(1.471e-01, 9.035e-02, -3.603e-01, 2.057e-02, 1.373e-01, -7.906e-02, -3.387e-01, 2.194e-02, -1.619e-01, -1.878e-02, -1.839e-01, -2.047e-02, 3.970e-01, -1.820e-02, 2.349e-01, 1.779e-01) * s0_1_0;
	r0 += M4(-2.259e-02, -5.355e-01, -3.100e-02, 6.854e-02, 5.806e-01, 4.557e-01, -9.644e-03, 9.861e-01, -9.985e-02, -2.770e-01, -2.087e-01, -7.612e-02, 2.921e-01, -4.047e-01, 4.444e-01, 3.669e-01) * s0_1_1;
	r1 += M4(-2.024e-01, 2.100e-01, -3.218e-01, 2.439e-03, 3.728e-01, -2.842e-01, 6.426e-01, 1.000e+00, -5.836e-01, -2.572e-01, -7.083e-01, -2.319e-01, -5.806e-01, -4.793e-01, -6.069e-01, 2.983e-01) * s0_1_1;
	r0 += M4(3.192e-02, -2.136e-01, 3.423e-02, 6.847e-02, -8.694e-02, 5.488e-01, -1.076e-01, -1.825e-03, -1.547e-01, 7.586e-02, -1.109e-01, -2.241e-01, -6.763e-02, -1.431e-01, -1.284e-01, -5.359e-02) * s0_1_2;
	r1 += M4(2.294e-01, 1.285e-01, 2.056e-01, 4.240e-03, -5.179e-01, -4.565e-01, -5.294e-01, -4.225e-01, 4.556e-01, -1.764e-01, 3.611e-01, -7.775e-02, -3.147e-01, -8.528e-01, -3.623e-01, -4.014e-01) * s0_1_2;
	r0 += M4(1.485e-03, -1.000e+00, -2.290e-01, -7.742e-02, -9.673e-02, 1.142e-01, -6.694e-01, -5.430e-02, -3.085e-02, 1.323e-01, -1.871e-01, -3.397e-02, -2.025e-01, -3.948e-01, -4.295e-01, 1.623e-01) * s0_2_0;
	r1 += M4(8.745e-03, -2.762e-02, -2.441e-01, -6.064e-02, 1.663e-01, 9.884e-02, -1.222e-01, -3.194e-02, 2.313e-03, 6.519e-03, -8.790e-02, -2.516e-02, -1.811e-01, 4.204e-02, -8.774e-02, 5.533e-02) * s0_2_0;
	r0 += M4(1.327e-02, -1.120e-01, -2.419e-01, -1.326e-01, -2.704e-01, -5.725e-01, 7.324e-01, 2.938e-01, 8.266e-03, -3.111e-01, -1.136e-03, 4.629e-03, 4.797e-02, -1.957e-01, 4.934e-01, 1.125e-01) * s0_2_1;
	r1 += M4(1.976e-01, -1.987e-01, 4.166e-01, -5.730e-02, 5.446e-01, 2.806e-01, 2.248e-01, 2.427e-01, -1.407e-01, 1.204e-01, -3.129e-01, -7.872e-03, 1.608e-01, 1.871e-01, -2.598e-01, -2.616e-02) * s0_2_1;
	r0 += M4(1.996e-02, -3.535e-01, -1.148e-02, -2.325e-02, -3.135e-01, 3.690e-01, 2.304e-02, -8.864e-02, -8.084e-02, -5.569e-03, -3.584e-01, 3.452e-02, 3.796e-02, 1.145e-01, -1.763e-01, -4.879e-02) * s0_2_2;
	r1 += M4(1.258e-01, -5.108e-01, 9.238e-02, -4.832e-02, -7.378e-01, 4.929e-01, -3.802e-01, -2.114e-01, 2.264e-01, -1.537e-01, -3.310e-02, -4.474e-02, 1.722e-01, 4.285e-01, -2.935e-01, -5.542e-02) * s0_2_2;
	r0 += M4(-4.367e-02, 1.000e+00, -3.047e-02, -1.743e-01, -4.643e-02, 3.350e-01, -1.683e-01, 6.235e-02, -1.028e-01, 4.466e-01, -1.335e-02, 3.219e-01, 6.029e-03, 2.346e-01, -1.470e-02, 2.057e-02) * s1_0_0;
	r1 += M4(-9.847e-02, 3.577e-02, -4.104e-01, -1.181e-01, -4.706e-02, -7.186e-03, 3.191e-01, 7.898e-03, -8.993e-01, 7.763e-02, -2.434e-01, -1.642e-01, 9.614e-04, -2.724e-02, 2.549e-01, 5.719e-02) * s1_0_0;
	r0 += M4(-1.262e-01, -2.040e-01, 8.811e-02, 8.029e-01, 6.860e-02, -1.720e-01, 8.492e-02, 2.032e-01, 1.587e-01, -3.194e-01, 4.427e-02, 5.383e-02, -1.180e-03, -2.036e-01, -5.674e-02, -4.061e-01) * s1_0_1;
	r1 += M4(1.013e-01, 1.907e-01, 4.133e-01, -1.944e-01, -3.061e-01, -3.450e-02, -8.672e-02, 9.633e-02, 1.715e-01, 7.940e-02, 4.991e-02, 3.246e-01, -3.861e-02, -5.091e-02, -2.994e-01, -5.214e-02) * s1_0_1;
	r0 += M4(1.910e-01, -3.109e-01, 8.399e-03, 1.516e-01, 1.592e-02, -8.407e-02, 2.524e-02, 7.156e-02, -1.251e-02, 1.238e-01, -7.312e-02, -3.137e-02, -1.076e-02, -1.104e-01, 4.904e-02, -3.622e-02) * s1_0_2;
	r1 += M4(1.350e-01, -1.296e-02, 3.295e-01, 4.941e-01, -7.766e-02, -3.429e-02, -1.033e-01, 6.118e-02, -1.960e-01, -2.026e-01, 3.799e-02, -9.472e-02, -3.071e-02, -1.170e-01, -1.593e-01, -8.813e-02) * s1_0_2;
	r0 += M4(4.578e-02, -2.718e-01, 4.092e-01, -1.917e-01, -7.973e-02, 2.416e-01, -8.960e-02, -4.566e-02, 7.324e-01, 1.918e-01, -3.850e-01, -2.377e-02, -8.028e-02, -9.207e-01, 2.337e-01, -3.744e-02) * s1_1_0;
	r1 += M4(-8.516e-01, -7.503e-02, 1.841e-01, -3.288e-02, -4.371e-01, 4.570e-02, 9.765e-01, 1.858e-02, -2.599e-01, -3.997e-01, 6.787e-02, 2.753e-01, 3.780e-02, 7.495e-02, 3.548e-01, -1.199e-01) * s1_1_0;
	r0 += M4(-4.902e-01, 9.653e-02, -6.154e-01, -3.596e-01, -1.024e-01, 2.982e-01, 5.510e-02, -9.485e-03, 3.936e-01, -2.446e-01, -7.408e-02, 1.986e-01, -6.050e-02, 2.008e-02, -2.588e-01, -1.867e-01) * s1_1_1;
	r1 += M4(-3.846e-01, -4.616e-02, -3.627e-01, -6.855e-01, -1.000e+00, 1.684e-01, -5.176e-01, -8.209e-02, 6.560e-01, -1.000e+00, -3.582e-01, 1.465e-01, -8.377e-01, -7.974e-02, -1.000e+00, -1.168e-01) * s1_1_1;
	r0 += M4(4.037e-01, -4.487e-01, 1.112e-01, -1.376e-01, -2.042e-02, -3.006e-02, -1.429e-02, -8.377e-02, -1.352e-02, -2.272e-02, -3.199e-02, 2.673e-02, 5.690e-02, 1.998e-01, 3.796e-02, 1.427e-01) * s1_1_2;
	r1 += M4(1.000e+00, -9.142e-02, -2.199e-01, 5.132e-01, -1.056e-01, 4.130e-01, 6.319e-03, -1.253e-01, 1.417e-02, 1.872e-01, 6.027e-02, -1.462e-03, 1.020e-01, 7.064e-01, 7.991e-01, 7.068e-01) * s1_1_2;
	r0 += M4(-3.536e-02, 7.207e-01, -1.601e-01, -1.900e-01, -1.419e-02, 2.105e-01, 3.108e-02, 3.649e-02, -4.117e-02, 6.217e-02, 9.667e-02, -2.447e-02, 1.343e-01, 2.434e-01, 8.291e-01, 4.402e-03) * s1_2_0;
	r1 += M4(-4.533e-02, -9.988e-02, 5.261e-02, -9.327e-02, 1.184e-01, -3.920e-02, 3.517e-01, 4.454e-03, -2.173e-01, 7.647e-02, 6.941e-03, -1.051e-02, 8.356e-02, -4.922e-02, 3.101e-01, 8.024e-02) * s1_2_0;
	r0 += M4(1.403e-01, -1.685e-01, -2.742e-01, 6.015e-02, 2.071e-02, 1.262e-01, 4.053e-01, -4.284e-02, 4.703e-02, -1.639e-01, 1.792e-02, -1.784e-02, 6.167e-02, -2.379e-01, -2.982e-01, -1.140e-01) * s1_2_1;
	r1 += M4(3.065e-01, 4.248e-01, -1.526e-02, 5.205e-02, -6.533e-01, -2.825e-02, 6.199e-02, 9.159e-02, 2.446e-01, 1.000e+00, -3.152e-02, 3.133e-02, 3.809e-01, 3.626e-02, -3.033e-01, 1.946e-01) * s1_2_1;
	r0 += M4(-9.740e-02, -4.383e-01, 4.255e-01, 4.282e-02, 1.448e-02, 5.511e-02, 2.105e-02, 2.959e-02, -1.054e-02, -5.376e-02, -3.478e-02, -1.116e-02, -5.619e-03, -7.187e-02, 1.846e-01, -1.777e-02) * s1_2_2;
	r1 += M4(-1.582e-01, -3.398e-01, -1.089e-02, 2.464e-02, -7.678e-02, -2.842e-01, -7.055e-02, -2.196e-03, 9.605e-02, 1.840e-01, 5.911e-02, -9.934e-03, -1.490e-01, -4.090e-01, 1.989e-01, 1.354e-02) * s1_2_2;
	r0 += V4(-1.810e-03, -7.263e-03, -6.213e-03, -6.183e-03);
	r0 = max(r0, V4(0.0));
	imageStore(out_image, opos + ivec2(0, 0), vec4(r0));
	r1 += V4(-7.251e-03, -4.239e-03, -9.470e-03, -2.777e-03);
	r1 = max(r1, V4(0.0));
	imageStore(out_image, opos + ivec2(1, 0), vec4(r1));
}

//!DESC [CuNNy_1x8] -out-shuffle
//!HOOK LUMA
//!COMPUTE 16 16 8 8
//!BIND conv1
//!BIND LUMA
//!WIDTH LUMA.w 2 *
//!HEIGHT LUMA.h 2 *
//!COMPONENTS 1
//!WHEN OUTPUT.w LUMA.w / 1.2 > OUTPUT.h LUMA.h / 1.2 > *
#extension GL_EXT_shader_explicit_arithmetic_types_float16 : enable
#ifdef GL_EXT_shader_explicit_arithmetic_types_float16
#	define V4 f16vec4
#	define M4 f16mat4
#	define F float16_t
#else
#	define V4 vec4
#	define M4 mat4
#	define F float
#endif
#define l0(x, y) V4(conv1_tex((vec2(clamp(pos + ivec2(x, y), ivec2(0), sz) * ivec2(2, 1) + ivec2(0, 0)) + vec2(0.5)) * conv1_pt))
#define l1(x, y) V4(conv1_tex((vec2(clamp(pos + ivec2(x, y), ivec2(0), sz) * ivec2(2, 1) + ivec2(1, 0)) + vec2(0.5)) * conv1_pt))
shared V4 G[2][10][10];
void hook() {
	ivec2 xy = ivec2(gl_LocalInvocationID.xy);
	ivec2 pos = ivec2(gl_WorkGroupID.xy) * ivec2(8, 8) + xy;
	ivec2 opos = pos * ivec2(2, 2);
	ivec2 sz = ivec2(LUMA_size) - ivec2(1);
	for (int y = 0; y < 10; y += 8) {
		int ay = xy.y + y;
		if (ay >= 10) break;
		for (int x = 0; x < 10; x += 8) {
			int ax = xy.x + x;
			if (ax >= 10) break;
			G[0][ay][ax] = l0(x - 1, y - 1);
			G[1][ay][ax] = l1(x - 1, y - 1);
		}
	}
	barrier();
	V4 s0_0_0, s0_0_1, s0_0_2, s0_1_0, s0_1_1, s0_1_2, s0_2_0, s0_2_1, s0_2_2, s1_0_0, s1_0_1, s1_0_2, s1_1_0, s1_1_1, s1_1_2, s1_2_0, s1_2_1, s1_2_2;
	V4 r0;
	r0 = V4(0.0);
	s0_0_0 = G[0][xy.y+0][xy.x+0]; s0_0_1 = G[0][xy.y+0][xy.x+1];
	s0_0_2 = G[0][xy.y+0][xy.x+2]; s0_1_0 = G[0][xy.y+1][xy.x+0];
	s0_1_1 = G[0][xy.y+1][xy.x+1]; s0_1_2 = G[0][xy.y+1][xy.x+2];
	s0_2_0 = G[0][xy.y+2][xy.x+0]; s0_2_1 = G[0][xy.y+2][xy.x+1];
	s0_2_2 = G[0][xy.y+2][xy.x+2]; s1_0_0 = G[1][xy.y+0][xy.x+0];
	s1_0_1 = G[1][xy.y+0][xy.x+1]; s1_0_2 = G[1][xy.y+0][xy.x+2];
	s1_1_0 = G[1][xy.y+1][xy.x+0]; s1_1_1 = G[1][xy.y+1][xy.x+1];
	s1_1_2 = G[1][xy.y+1][xy.x+2]; s1_2_0 = G[1][xy.y+2][xy.x+0];
	s1_2_1 = G[1][xy.y+2][xy.x+1]; s1_2_2 = G[1][xy.y+2][xy.x+2];
	r0 += M4(3.788e-02, -2.202e-02, 6.274e-02, -6.360e-02, -1.171e-02, -6.032e-03, 5.383e-03, -9.737e-05, 2.339e-02, 3.258e-02, -2.534e-02, 3.834e-02, -4.016e-02, -9.612e-03, 1.407e-02, -3.169e-03) * s0_0_0;
	r0 += M4(2.549e-01, 3.096e-01, -1.370e-02, 1.104e-01, 1.203e-02, 2.493e-03, -2.289e-02, 4.013e-03, 6.113e-01, -7.518e-01, 2.349e-01, -3.193e-01, -5.090e-02, -7.690e-02, 3.547e-02, 1.095e-02) * s0_0_1;
	r0 += M4(-4.094e-04, 4.871e-02, -2.334e-03, -2.960e-02, 1.273e-02, 3.619e-02, -3.189e-02, -3.805e-02, -8.413e-02, 3.038e-01, -2.374e-02, 8.183e-02, -9.839e-03, 4.622e-03, -2.402e-03, 4.007e-03) * s0_0_2;
	r0 += M4(-9.597e-02, 3.918e-02, -2.998e-01, 9.985e-02, 1.791e-02, -1.012e-02, -7.399e-03, -3.979e-03, -7.831e-02, 3.546e-02, 1.857e-03, 4.797e-02, -6.567e-02, -9.880e-03, -2.456e-01, 2.521e-02) * s0_1_0;
	r0 += M4(-4.632e-01, -6.033e-01, 4.515e-01, 4.974e-02, -2.644e-01, 6.042e-02, 2.881e-01, 1.551e-02, 4.267e-02, -6.850e-02, 3.173e-01, -5.598e-01, 2.113e-01, 4.907e-02, -6.541e-02, -3.086e-01) * s0_1_1;
	r0 += M4(-1.734e-02, 6.370e-03, -3.822e-03, 1.370e-01, 3.692e-03, -4.321e-01, 2.504e-02, 3.587e-01, 3.973e-02, 4.270e-02, -4.145e-02, 2.637e-01, -3.795e-02, 6.275e-02, -1.331e-02, 1.778e-02) * s0_1_2;
	r0 += M4(-1.443e-02, -1.978e-02, 5.628e-02, -3.552e-02, 1.669e-02, 2.666e-03, -3.273e-03, 5.679e-04, -4.915e-03, -4.293e-03, -5.227e-02, -8.799e-03, -4.159e-02, -8.032e-02, 1.284e-01, -1.042e-01) * s0_2_0;
	r0 += M4(1.392e-01, 1.204e-01, -6.640e-02, -6.692e-02, 1.377e-01, 9.153e-02, -2.376e-01, 1.333e-03, -3.279e-02, -3.410e-02, 7.565e-03, 1.359e-02, 4.626e-02, 1.099e-01, 1.605e-01, 3.682e-01) * s0_2_1;
	r0 += M4(2.758e-02, 2.605e-02, -1.287e-02, 1.161e-02, -6.324e-02, 8.570e-02, 1.539e-01, -8.862e-02, 7.079e-03, 2.946e-02, 2.284e-02, 2.152e-02, -6.437e-03, -3.748e-02, -2.361e-02, -2.870e-02) * s0_2_2;
	r0 += M4(-5.281e-01, -1.457e-01, 4.129e-01, 1.208e-01, 3.721e-01, 2.995e-01, -3.727e-01, -4.990e-01, -1.236e-02, -4.197e-03, -1.842e-02, 5.041e-03, 3.112e-02, 2.227e-02, -5.921e-02, 4.529e-02) * s1_0_0;
	r0 += M4(1.685e-01, -4.268e-01, 9.174e-02, 3.779e-01, 1.639e-02, 6.421e-02, -2.579e-02, 3.326e-03, -1.929e-01, 1.577e-01, 7.202e-02, -4.533e-02, -3.646e-02, -6.408e-02, -5.115e-02, -5.308e-02) * s1_0_1;
	r0 += M4(-2.103e-02, 1.135e-01, -2.691e-02, -5.387e-02, 5.693e-03, -8.161e-03, -1.067e-03, 7.965e-03, 3.350e-02, 1.728e-02, 2.234e-02, -7.977e-03, 1.103e-02, -4.748e-02, -1.474e-03, -5.858e-03) * s1_0_2;
	r0 += M4(1.188e-02, -2.366e-02, -1.294e-02, 4.071e-02, -1.323e-01, -1.167e-01, 4.421e-02, 9.839e-02, 2.981e-02, -4.920e-02, 4.358e-02, -6.639e-02, 2.712e-01, -3.215e-02, 4.379e-01, -9.529e-02) * s1_1_0;
	r0 += M4(4.052e-01, 4.141e-01, -4.365e-01, -3.387e-01, -1.233e-02, -5.412e-03, 2.472e-02, -1.433e-03, -5.137e-01, 2.864e-01, -6.905e-01, 5.042e-01, -3.330e-01, 2.607e-01, -1.850e-01, 2.465e-01) * s1_1_1;
	r0 += M4(-1.197e-02, 1.498e-02, 4.959e-02, -3.216e-02, -2.470e-03, -1.149e-03, 8.296e-04, 6.726e-03, 5.140e-02, 9.094e-02, 5.011e-02, 1.027e-01, 3.137e-02, -1.509e-01, 2.863e-02, -1.057e-01) * s1_1_2;
	r0 += M4(1.426e-02, 2.986e-03, -4.974e-02, 4.719e-03, 6.685e-04, 9.693e-04, 5.386e-04, 2.119e-03, -3.664e-04, 9.126e-03, -8.559e-04, 1.280e-02, 2.028e-02, 7.202e-02, -5.538e-02, 1.032e-01) * s1_2_0;
	r0 += M4(-6.518e-02, -2.118e-02, 8.566e-02, -3.080e-02, -7.248e-04, -1.857e-03, -1.003e-03, -3.177e-04, 7.956e-02, -6.891e-02, 3.575e-02, -8.273e-02, 2.912e-02, -4.895e-02, -1.265e-01, -6.982e-02) * s1_2_1;
	r0 += M4(-1.640e-02, -3.974e-02, 1.851e-02, 5.310e-02, 1.279e-03, 1.490e-03, -5.668e-04, -1.943e-03, 5.968e-03, -1.037e-02, 1.819e-02, -1.592e-05, -2.509e-02, -1.059e-02, -4.010e-03, -9.012e-02) * s1_2_2;
	r0 += V4(-8.458e-05, -5.883e-05, -1.067e-04, -9.416e-05);
	r0 = tanh(r0);
	vec2 opt = 0.5 * LUMA_pt;
	vec2 fpos = (vec2(opos) + vec2(0.5)) * opt;
	imageStore(out_image, opos + ivec2(0, 0), vec4(r0.x + LUMA_tex(fpos + vec2(0.0, 0.0) * opt).r, 0.0, 0.0, 1.0));
	imageStore(out_image, opos + ivec2(1, 0), vec4(r0.y + LUMA_tex(fpos + vec2(1.0, 0.0) * opt).r, 0.0, 0.0, 1.0));
	imageStore(out_image, opos + ivec2(0, 1), vec4(r0.z + LUMA_tex(fpos + vec2(0.0, 1.0) * opt).r, 0.0, 0.0, 1.0));
	imageStore(out_image, opos + ivec2(1, 1), vec4(r0.w + LUMA_tex(fpos + vec2(1.0, 1.0) * opt).r, 0.0, 0.0, 1.0));
}
